abundances = {
    's1.t1': [1,1,1,1,1],
    's1.t2': [9,0,9,0,9],
    's2.t1': [6,8,3,1,9],
    's2.t2': [6,8,3,1,9]
}
import csv

SAMPLE_FACTOR = 1000
SAMPLE = 'sample'

genomes = {
    'g1': 'B_eggerthiiDSM20697.g1',
    'g2': 'B_uniformisCL03T00C23.g2',
    'g3': 'B_fragilisNCTC9343.g3',
    'g4': 'B_Sp325.g4',
    'g5': 'B_fragilisHMW615.g5'
}
genomes_rev = {val:key for key, val in genomes.items()}


def read_csv(fn):
    with open(fn) as inf:
        reader = csv.DictReader(inf)
        rows = {row[SAMPLE]:row for row in reader}
    return rows, reader.fieldnames

def get_nreads(wc, input):
    abundances, fieldnames = read_csv(input.abundances)
    genome_id = genomes_rev[wc.genome]
    return float(abundances[wc.sample][genome_id]) * SAMPLE_FACTOR

def get_readfiles(wc):
    abundances, fieldnames = read_csv("{}_abundances.csv".format(wc.set))
    return expand("{set}.{sample}.{rf}.fq.gz",
                  set=wc.set,
                  sample=abundances.keys(),
                  rf='R1 R2'.split())    

wildcard_constraints:
    set = "[^.]+",
    sample = "[^.]+",
    genome = "(" + "|".join(genomes.values()) +")"

sets, = glob_wildcards("{set}_abundances.csv")
rule all:
    input: expand("{set}_map.csv", set=sets), "genomes.fasta.gz"

rule gzip:
    input:
       "{file}"
    output:
       "{file}.gz"
    shell:
       "gzip -c {input} > {output}"

rule genomes_file:
    input:
        expand("{g}.fasta", g=genomes.values())
    output:
        "genomes.fasta.gz"
    params:
        g = list(genomes.keys())
    shell: """
    set -- {params.g}
    for f in {input:q}; do
      sed 's/^>/>'$1' /' $f
      shift
    done | gzip -c > {output}
    """

rule mapping_file:
    input:
       '{set}_abundances.csv',
       get_readfiles
    output:
       '{set}_map.csv'
    run:
       abundances, fieldnames = read_csv(input[0])
       fieldnames.extend(['fq1','fq2'])
       with open(output[0], "w") as out:
          import csv
          writer = csv.DictWriter(out, fieldnames=fieldnames)
          writer.writeheader()
          for sample in abundances.values():
              for n in ('1','2'):
                  sample['fq'+n] = ".".join((wildcards.set, sample[SAMPLE], "R"+n, "fq.gz"))
              writer.writerow(sample)

rule simulate_reads:
    input:
        "{genome}.fasta"
    output:
        fq1 = temp("{genome}.R1.fq"),
        fq2 = temp("{genome}.R2.fq")
    params:
        insert_size = 10*15,
        coverage=1000,
        sdev=150
    shadow: "shallow"
    conda: "art.yaml"
    shell: """
    art_illumina \
    --in {input} \
    --out out \
    --mflen {params.insert_size} \
    --paired \
    --len 100 \
    --fcov {params.coverage} \
    --seqSys HS20 \
    --noALN \
    --sdev {params.sdev}

    mv out1.fq {output.fq1}
    mv out2.fq {output.fq2}
    """

rule sample_reads:
    output:
        fq1=temp('{set}.{sample}.{genome}.R1.fq'),
        fq2=temp('{set}.{sample}.{genome}.R2.fq')
    input:
        fq1 = "{genome}.R1.fq",
        fq2 = "{genome}.R2.fq",
        abundances  = "{set}_abundances.csv"
    params:
        nreads = get_nreads
    shell: """
    reformat.sh in={input.fq1} in2={input.fq2} out={output.fq1} \
                out2={output.fq2} sample={params.nreads}
    """

rule merge_read_files:
    output:
        temp("{set}.{sample}.{r}.fq")
    input:
        expand('{{set}}.{{sample}}.{genome}.{{r}}.fq', genome=genomes.values())
    wildcard_constraints:
        r="R[12]"
    shell: """
    cat {input} > {output}
    """
